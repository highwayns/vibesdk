#!/usr/bin/env python3
"""åŒæ­¥ Agent-Skills-for-Context-Engineering ä»“åº“çš„ skills åˆ°æœ¬åœ°.

æ­¤è„šæœ¬ä» GitHub ä»“åº“ muratcankoylan/Agent-Skills-for-Context-Engineering 
ä¸‹è½½æœ€æ–°çš„ context engineering skillsï¼ŒåŒ…æ‹¬å…³è”çš„ scripts/ã€references/ ç›®å½•ã€‚

Usage:
    python scripts/sync_skills.py --target-dir .claude/skills --force --full
    
Options:
    --target-dir    ç›®æ ‡ç›®å½•ï¼Œé»˜è®¤ä¸º skills/
    --force         å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
    --dry-run       ä»…æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…ä¸‹è½½
    --include       ä»…åŒæ­¥æŒ‡å®šçš„ skills (é€—å·åˆ†éš”)
    --exclude       æ’é™¤æŒ‡å®šçš„ skills (é€—å·åˆ†éš”)
    --full          åŒæ­¥å®Œæ•´ç›®å½•ç»“æ„ (åŒ…æ‹¬ scripts/, references/, assets/)
    --flat          ä»…åŒæ­¥ SKILL.md ä¸ºæ‰å¹³ç»“æ„ (é»˜è®¤)
    --analyze       åˆ†æé¡¹ç›®ä¸­ skills çš„ä½¿ç”¨æƒ…å†µ

ä¸Šæ¸¸ Skill ç›®å½•ç»“æ„:
    skill-name/
    â”œâ”€â”€ SKILL.md         # å¿…éœ€ï¼šä¸»æŒ‡ä»¤æ–‡ä»¶ (frontmatter + instructions)
    â”œâ”€â”€ scripts/         # å¯é€‰ï¼šå¯æ‰§è¡Œè„šæœ¬ (Python/Bash)
    â”œâ”€â”€ references/      # å¯é€‰ï¼šå‚è€ƒæ–‡æ¡£
    â””â”€â”€ assets/          # å¯é€‰ï¼šæ¨¡æ¿å’Œèµ„æºæ–‡ä»¶

ä¿®å¤ç‰ˆæœ¬: æ·»åŠ äº†åŠ¨æ€å‘ç°å­ç›®å½•æ–‡ä»¶çš„åŠŸèƒ½
"""

from __future__ import annotations

import argparse
import hashlib
import json
import os
import re
import shutil
import sys
import urllib.request
import urllib.error
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple


# =============================================================================
# Configuration
# =============================================================================

GITHUB_REPO = "muratcankoylan/Agent-Skills-for-Context-Engineering"
GITHUB_BRANCH = "main"
GITHUB_RAW_BASE = f"https://raw.githubusercontent.com/{GITHUB_REPO}/{GITHUB_BRANCH}"
GITHUB_API_BASE = f"https://api.github.com/repos/{GITHUB_REPO}"

# Known skills from the repository (based on documentation and search results)
# æ¯ä¸ª skill æ˜¯ä¸€ä¸ªç›®å½•ï¼ŒåŒ…å« SKILL.md å’Œå¯èƒ½çš„å…¶ä»–æ–‡ä»¶
KNOWN_SKILLS = [
    # Context Engineering Fundamentals (åŸºç¡€)
    "context-fundamentals",
    "context-degradation", 
    "context-optimization",
    
    # Agent Architecture (æ¶æ„)
    "multi-agent-patterns",
    "memory-systems",
    "tool-design",
    
    # Evaluation & Development (è¯„ä¼°ä¸å¼€å‘)
    "evaluation",
    "agent-evaluation",
    "agent-development",
    
    # Advanced (é«˜çº§)
    "agent-architecture",
    "cognitive-architecture",
    
    # Specialized (ä¸“é—¨åŒ–)
    "background-agents",
    "llm-project-development",
]

# æ¯ä¸ª skill ç›®å½•ä¸‹å¯èƒ½åŒ…å«çš„å­ç›®å½•
SKILL_SUBDIRS = ["scripts", "references", "assets"]

# æ¯ä¸ª skill ç›®å½•ä¸‹å·²çŸ¥çš„æ–‡ä»¶ (åŸºäºæ–‡æ¡£å’Œæœç´¢ç»“æœ)
# æ ¼å¼: skill_name -> [(subdir, filename), ...]
# æ³¨æ„: è¿™ä¸ªåˆ—è¡¨ç°åœ¨ä»…ä½œä¸ºåå¤‡æ–¹æ¡ˆï¼Œä¸»è¦ä¾èµ–åŠ¨æ€å‘ç°
KNOWN_SKILL_FILES: Dict[str, List[Tuple[str, str]]] = {
    "context-fundamentals": [
        ("scripts", "progressive_disclosure.py"),
    ],
    "context-optimization": [
        ("scripts", "compaction.py"),
        ("scripts", "observation_masking.py"),
    ],
    "memory-systems": [
        ("scripts", "vector_store.py"),
        ("scripts", "knowledge_graph.py"),
    ],
    "tool-design": [
        ("scripts", "tool_wrapper.py"),
        ("references", "tool_patterns.md"),
    ],
    "evaluation": [
        ("scripts", "evaluator.py"),
        ("references", "metrics.md"),
    ],
    "multi-agent-patterns": [
        ("scripts", "orchestrator.py"),
        ("scripts", "swarm.py"),
    ],
}

# Mapping: æœ¬åœ°æ—§æ–‡ä»¶å -> å¯¹åº”çš„æ–° skill ç›®å½•
LOCAL_TO_UPSTREAM_MAPPING = {
    "context-fundamentals.md": "context-fundamentals",
    "context-degradation.md": "context-degradation",
    "context-compression.md": "context-optimization",
    "memory-systems.md": "memory-systems",
    "filesystem-context.md": None,
}


@dataclass
class SkillInfo:
    """Skill å…ƒä¿¡æ¯"""
    name: str
    summary: str = ""
    version: str = "1.0.0"
    file: str = "SKILL.md"
    local_file: str = ""
    upstream_dir: str = ""
    triggers: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    hash: str = ""


@dataclass
class SyncResult:
    """åŒæ­¥ç»“æœ"""
    skill: str
    action: str  # downloaded, updated, skipped, failed
    message: str = ""
    old_hash: str = ""
    new_hash: str = ""


# =============================================================================
# Utility Functions
# =============================================================================

def fetch_url(url: str, timeout: int = 30) -> Optional[str]:
    """ä» URL è·å–å†…å®¹"""
    try:
        req = urllib.request.Request(
            url,
            headers={"User-Agent": "better-agents-skill-sync/1.0"}
        )
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            return resp.read().decode("utf-8")
    except urllib.error.HTTPError as e:
        if e.code == 404:
            return None
        raise
    except Exception as e:
        print(f"Warning: Failed to fetch {url}: {e}", file=sys.stderr)
        return None


def fetch_json(url: str, timeout: int = 30) -> Optional[Any]:
    """ä» URL è·å– JSON å†…å®¹"""
    content = fetch_url(url, timeout)
    if content:
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            print(f"Warning: Failed to parse JSON from {url}: {e}", file=sys.stderr)
    return None


def compute_hash(content: str) -> str:
    """è®¡ç®—å†…å®¹çš„çŸ­ hash"""
    return hashlib.sha256(content.encode()).hexdigest()[:12]


def extract_skill_metadata(content: str) -> Dict[str, Any]:
    """ä» SKILL.md å†…å®¹ä¸­æå–å…ƒæ•°æ®"""
    metadata: Dict[str, Any] = {
        "summary": "",
        "version": "1.0.0",
        "triggers": [],
        "dependencies": [],
    }
    
    lines = content.split("\n")
    in_description = False
    description_lines = []
    
    for line in lines:
        if "Version:" in line:
            match = re.search(r"Version:\s*(\d+\.\d+\.\d+)", line)
            if match:
                metadata["version"] = match.group(1)
        
        if "should be used when" in line.lower():
            triggers = re.findall(r'"([^"]+)"', line)
            metadata["triggers"].extend(triggers)
        
        if "connects to:" in line.lower() or "builds on:" in line.lower():
            deps = re.findall(r'(\w+-\w+)', line)
            metadata["dependencies"].extend(deps)
        
        if line.startswith("# "):
            in_description = True
            continue
        if in_description and line.strip() and not line.startswith("#"):
            description_lines.append(line.strip())
            if len(description_lines) >= 3:
                break
    
    if description_lines:
        metadata["summary"] = " ".join(description_lines[:2])[:200]
    
    return metadata


def list_remote_skills() -> List[str]:
    """å°è¯•ä» GitHub API è·å– skills åˆ—è¡¨ï¼Œå¤±è´¥åˆ™ä½¿ç”¨å·²çŸ¥åˆ—è¡¨"""
    try:
        url = f"{GITHUB_API_BASE}/contents/skills"
        data = fetch_json(url)
        if data:
            return [item["name"] for item in data if item["type"] == "dir"]
    except Exception as e:
        print(f"Warning: Could not fetch skill list from API: {e}", file=sys.stderr)
    
    return KNOWN_SKILLS


# =============================================================================
# Sync Logic
# =============================================================================

class SkillSyncer:
    """Skills åŒæ­¥å™¨
    
    æ”¯æŒä¸¤ç§æ¨¡å¼:
    1. flat_structure=True (é»˜è®¤): ä»…ä¸‹è½½ SKILL.md ä¸ºæ‰å¹³æ–‡ä»¶
    2. flat_structure=False (--full): ä¸‹è½½å®Œæ•´ç›®å½•ç»“æ„åŒ…æ‹¬ scripts/, references/, assets/
    
    ä¿®å¤ç‰ˆæœ¬: æ·»åŠ äº†åŠ¨æ€å‘ç°å­ç›®å½•æ–‡ä»¶çš„åŠŸèƒ½
    """
    
    def __init__(
        self,
        target_dir: str = "skills",
        force: bool = False,
        dry_run: bool = False,
        include: Optional[Set[str]] = None,
        exclude: Optional[Set[str]] = None,
        flat_structure: bool = True,
    ):
        self.target_dir = Path(target_dir)
        self.force = force
        self.dry_run = dry_run
        self.include = include
        self.exclude = exclude or set()
        self.flat_structure = flat_structure
        self.results: List[SyncResult] = []
        self.file_results: List[SyncResult] = []
        # ç¼“å­˜å·²å‘ç°çš„æ–‡ä»¶åˆ—è¡¨ï¼Œé¿å…é‡å¤ API è°ƒç”¨
        self._discovered_files_cache: Dict[str, List[Tuple[str, str]]] = {}
    
    def should_sync(self, skill_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åŒæ­¥è¯¥ skill"""
        if self.include and skill_name not in self.include:
            return False
        if skill_name in self.exclude:
            return False
        return True
    
    def get_local_path(self, skill_name: str, subdir: str = "", filename: str = "SKILL.md") -> Path:
        """è·å–æœ¬åœ°è·¯å¾„"""
        if self.flat_structure:
            return self.target_dir / f"{skill_name}.md"
        
        if subdir:
            return self.target_dir / skill_name / subdir / filename
        return self.target_dir / skill_name / filename
    
    def get_remote_url(self, skill_name: str, subdir: str = "", filename: str = "SKILL.md") -> str:
        """è·å–è¿œç¨‹ URL"""
        if subdir:
            return f"{GITHUB_RAW_BASE}/skills/{skill_name}/{subdir}/{filename}"
        return f"{GITHUB_RAW_BASE}/skills/{skill_name}/{filename}"
    
    def _discover_skill_files(self, skill_name: str) -> List[Tuple[str, str]]:
        """åŠ¨æ€å‘ç° skill å­ç›®å½•ä¸­çš„æ–‡ä»¶ (ä¿®å¤æ ¸å¿ƒ)
        
        é€šè¿‡ GitHub API è·å–æ¯ä¸ªå­ç›®å½•çš„å®é™…æ–‡ä»¶åˆ—è¡¨ï¼Œ
        è€Œä¸æ˜¯ä¾èµ–ç¡¬ç¼–ç çš„ KNOWN_SKILL_FILESã€‚
        
        Returns:
            List of (subdir, filename) tuples
        """
        # æ£€æŸ¥ç¼“å­˜
        if skill_name in self._discovered_files_cache:
            return self._discovered_files_cache[skill_name]
        
        discovered_files: List[Tuple[str, str]] = []
        
        for subdir in SKILL_SUBDIRS:
            # ä½¿ç”¨ GitHub API è·å–å­ç›®å½•å†…å®¹
            url = f"{GITHUB_API_BASE}/contents/skills/{skill_name}/{subdir}"
            data = fetch_json(url)
            
            if data and isinstance(data, list):
                for item in data:
                    if item.get("type") == "file":
                        filename = item.get("name", "")
                        if filename:
                            discovered_files.append((subdir, filename))
                            
        # ç¼“å­˜ç»“æœ
        self._discovered_files_cache[skill_name] = discovered_files
        
        return discovered_files
    
    def _get_files_to_sync(self, skill_name: str) -> List[Tuple[str, str]]:
        """è·å–éœ€è¦åŒæ­¥çš„æ–‡ä»¶åˆ—è¡¨
        
        ä¼˜å…ˆä½¿ç”¨åŠ¨æ€å‘ç°ï¼Œå¦‚æœ API è°ƒç”¨å¤±è´¥åˆ™å›é€€åˆ°å·²çŸ¥æ–‡ä»¶åˆ—è¡¨ã€‚
        """
        # 1. å°è¯•åŠ¨æ€å‘ç°
        discovered = self._discover_skill_files(skill_name)
        
        # 2. è·å–å·²çŸ¥æ–‡ä»¶ä½œä¸ºåå¤‡
        known = KNOWN_SKILL_FILES.get(skill_name, [])
        
        # 3. åˆå¹¶å¹¶å»é‡
        all_files = list(discovered)
        for item in known:
            if item not in all_files:
                all_files.append(item)
        
        return all_files
    
    def sync_file(self, skill_name: str, subdir: str = "", filename: str = "SKILL.md") -> SyncResult:
        """åŒæ­¥å•ä¸ªæ–‡ä»¶"""
        local_path = self.get_local_path(skill_name, subdir, filename)
        remote_url = self.get_remote_url(skill_name, subdir, filename)
        
        # è·å–è¿œç¨‹å†…å®¹
        remote_content = fetch_url(remote_url)
        if not remote_content:
            return SyncResult(
                f"{skill_name}/{subdir}/{filename}" if subdir else f"{skill_name}/{filename}",
                "failed", 
                f"Not found or inaccessible"
            )
        
        new_hash = compute_hash(remote_content)
        
        # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶
        old_hash = ""
        if local_path.exists():
            try:
                local_content = local_path.read_text(encoding="utf-8")
                old_hash = compute_hash(local_content)
                
                if old_hash == new_hash and not self.force:
                    return SyncResult(
                        f"{skill_name}/{subdir}/{filename}" if subdir else f"{skill_name}/{filename}",
                        "skipped", 
                        "Up to date", 
                        old_hash, 
                        new_hash
                    )
            except Exception:
                pass
        
        # æ‰§è¡Œå†™å…¥
        if not self.dry_run:
            local_path.parent.mkdir(parents=True, exist_ok=True)
            local_path.write_text(remote_content, encoding="utf-8")
            action = "updated" if old_hash else "downloaded"
        else:
            action = "would_update" if old_hash else "would_download"
        
        file_id = f"{skill_name}/{subdir}/{filename}" if subdir else f"{skill_name}/{filename}"
        return SyncResult(file_id, action, "", old_hash, new_hash)
    
    def sync_skill(self, skill_name: str) -> SyncResult:
        """åŒæ­¥å•ä¸ª skill (åŒ…æ‹¬å…³è”ç›®å½•)"""
        if not self.should_sync(skill_name):
            return SyncResult(skill_name, "skipped", "Excluded by filter")
        
        # 1. åŒæ­¥ SKILL.md (å¿…éœ€)
        main_result = self.sync_file(skill_name)
        
        if main_result.action == "failed":
            return SyncResult(skill_name, "failed", main_result.message)
        
        # 2. å¦‚æœæ˜¯å®Œæ•´æ¨¡å¼ï¼ŒåŒæ­¥å…³è”ç›®å½•
        if not self.flat_structure:
            self._sync_skill_subdirs(skill_name)
        
        return main_result
    
    def _sync_skill_subdirs(self, skill_name: str) -> None:
        """åŒæ­¥ skill çš„å­ç›®å½• (scripts/, references/, assets/)
        
        ä¿®å¤ç‰ˆæœ¬: ä½¿ç”¨åŠ¨æ€å‘ç°è€Œä¸æ˜¯ç¡¬ç¼–ç åˆ—è¡¨
        """
        # è·å–éœ€è¦åŒæ­¥çš„æ–‡ä»¶åˆ—è¡¨ (åŠ¨æ€å‘ç° + å·²çŸ¥æ–‡ä»¶)
        files_to_sync = self._get_files_to_sync(skill_name)
        
        if not files_to_sync:
            # å¦‚æœæ²¡æœ‰å‘ç°ä»»ä½•æ–‡ä»¶ï¼Œå°è¯•å¸¸è§æ–‡ä»¶åä½œä¸ºæœ€åæ‰‹æ®µ
            common_files = [
                ("scripts", "example.py"),
                ("scripts", "demo.py"),
                ("scripts", "utils.py"),
                ("scripts", "main.py"),
                ("scripts", "__init__.py"),
                ("references", "README.md"),
                ("references", "examples.md"),
                ("references", "guide.md"),
                ("assets", "template.md"),
                ("assets", "config.yaml"),
                ("assets", "config.json"),
            ]
            files_to_sync = common_files
        
        synced_count = 0
        for subdir, filename in files_to_sync:
            result = self.sync_file(skill_name, subdir, filename)
            
            # åªè®°å½•éå¤±è´¥çš„ç»“æœï¼ˆåŠ¨æ€å‘ç°çš„æ–‡ä»¶åº”è¯¥éƒ½å­˜åœ¨ï¼‰
            if result.action != "failed":
                self.file_results.append(result)
                synced_count += 1
                
                if result.action not in ("skipped",):
                    icon = "  âœ“" if result.action == "downloaded" else "  â†‘"
                    print(f"    {icon} {subdir}/{filename}")
            elif result.action == "failed" and (subdir, filename) in KNOWN_SKILL_FILES.get(skill_name, []):
                # åªå¯¹å·²çŸ¥æ–‡ä»¶æŠ¥å‘Šå¤±è´¥
                self.file_results.append(result)
                print(f"    âœ— {subdir}/{filename}: {result.message}")
    
    def sync_all(self) -> List[SyncResult]:
        """åŒæ­¥æ‰€æœ‰ skills"""
        print(f"Fetching skill list from {GITHUB_REPO}...")
        skills = list_remote_skills()
        
        mode = "å®Œæ•´ç›®å½• (åŠ¨æ€å‘ç°)" if not self.flat_structure else "æ‰å¹³æ–‡ä»¶"
        print(f"Found {len(skills)} skills to sync (æ¨¡å¼: {mode})")
        print("")
        
        for skill in skills:
            result = self.sync_skill(skill)
            self.results.append(result)
            
            icon = {
                "downloaded": "âœ“",
                "updated": "â†‘",
                "skipped": "Â·",
                "failed": "âœ—",
                "would_download": "?",
                "would_update": "?",
            }.get(result.action, "?")
            
            print(f"  {icon} {result.skill}: {result.action} {result.message}")
        
        return self.results
    
    def generate_index(self) -> Dict[str, Dict[str, Any]]:
        """ç”Ÿæˆ skill_index.json"""
        index: Dict[str, Dict[str, Any]] = {}
        
        if self.flat_structure:
            skill_files = list(self.target_dir.glob("*.md"))
        else:
            skill_files = list(self.target_dir.glob("*/SKILL.md"))
        
        for path in skill_files:
            if path.name == "README.md":
                continue
            
            skill_name = path.stem if self.flat_structure else path.parent.name
            content = path.read_text(encoding="utf-8")
            metadata = extract_skill_metadata(content)
            
            entry: Dict[str, Any] = {
                "summary": metadata["summary"],
                "file": path.name if self.flat_structure else f"{skill_name}/SKILL.md",
                "version": metadata["version"],
                "triggers": metadata["triggers"][:5],
            }
            
            if not self.flat_structure:
                skill_dir = self.target_dir / skill_name
                associated_files = []
                
                for subdir in SKILL_SUBDIRS:
                    subdir_path = skill_dir / subdir
                    if subdir_path.exists():
                        for f in subdir_path.iterdir():
                            if f.is_file():
                                associated_files.append(f"{subdir}/{f.name}")
                
                if associated_files:
                    entry["associated_files"] = associated_files
            
            index[skill_name] = entry
        
        return index
    
    def save_index(self) -> Path:
        """ä¿å­˜ skill_index.json"""
        index = self.generate_index()
        index_path = self.target_dir / "skill_index.json"
        
        if not self.dry_run:
            index_path.write_text(
                json.dumps(index, indent=2, ensure_ascii=False),
                encoding="utf-8"
            )
        
        return index_path
    
    def print_summary(self) -> None:
        """æ‰“å°åŒæ­¥æ‘˜è¦"""
        downloaded = sum(1 for r in self.results if r.action in ("downloaded", "updated"))
        skipped = sum(1 for r in self.results if r.action == "skipped")
        failed = sum(1 for r in self.results if r.action == "failed")
        
        print(f"\nä¸»æ–‡ä»¶æ‘˜è¦: {downloaded} åŒæ­¥, {skipped} è·³è¿‡, {failed} å¤±è´¥")
        
        if self.file_results:
            sub_downloaded = sum(1 for r in self.file_results if r.action in ("downloaded", "updated"))
            sub_skipped = sum(1 for r in self.file_results if r.action == "skipped")
            sub_failed = sum(1 for r in self.file_results if r.action == "failed")
            print(f"å…³è”æ–‡ä»¶: {sub_downloaded} åŒæ­¥, {sub_skipped} è·³è¿‡, {sub_failed} å¤±è´¥")
            
            # æ˜¾ç¤ºå‘ç°ç»Ÿè®¡
            total_discovered = sum(len(files) for files in self._discovered_files_cache.values())
            if total_discovered > 0:
                print(f"åŠ¨æ€å‘ç°: å…±å‘ç° {total_discovered} ä¸ªå­ç›®å½•æ–‡ä»¶")


# =============================================================================
# Necessity Analysis
# =============================================================================

def analyze_file_necessity() -> Dict[str, Any]:
    """åˆ†æå…³è”æ–‡ä»¶çš„å¤åˆ¶å¿…è¦æ€§"""
    analysis = {
        "å¿…éœ€å¤åˆ¶": [],
        "å»ºè®®å¤åˆ¶": [],
        "å¯é€‰å¤åˆ¶": [],
        "æ— éœ€å¤åˆ¶": [],
    }
    
    file_necessity = {
        "scripts/progressive_disclosure.py": {
            "necessity": "å»ºè®®å¤åˆ¶",
            "reason": "æ¼”ç¤ºæ¸è¿›å¼åŠ è½½æ¨¡å¼ï¼Œå¯ä½œä¸º SkillsPack å®ç°çš„å‚è€ƒ",
            "used_by": ["skills_loader.py"],
        },
        "scripts/compaction.py": {
            "necessity": "å»ºè®®å¤åˆ¶",
            "reason": "å‹ç¼©ç®—æ³•ç¤ºä¾‹ï¼Œå¯ä½œä¸º compressor.py çš„å‚è€ƒ",
            "used_by": ["compressor.py"],
        },
        "scripts/observation_masking.py": {
            "necessity": "å¯é€‰å¤åˆ¶",
            "reason": "è§‚å¯Ÿæ©ç æŠ€æœ¯ï¼Œå½“å‰ä»£ç æœªä½¿ç”¨æ­¤æ¨¡å¼",
            "used_by": [],
        },
        "scripts/vector_store.py": {
            "necessity": "å¯é€‰å¤åˆ¶",
            "reason": "å‘é‡å­˜å‚¨ç¤ºä¾‹ï¼Œå½“å‰ä½¿ç”¨ RAGFlow è€Œéæœ¬åœ°å‘é‡åº“",
            "used_by": [],
        },
        "scripts/knowledge_graph.py": {
            "necessity": "å¯é€‰å¤åˆ¶",
            "reason": "çŸ¥è¯†å›¾è°±ç¤ºä¾‹ï¼Œå½“å‰ç‰ˆæœ¬æœªå®ç°",
            "used_by": [],
        },
        "scripts/tool_wrapper.py": {
            "necessity": "å»ºè®®å¤åˆ¶",
            "reason": "Tool å®šä¹‰æœ€ä½³å®è·µï¼Œå¯¹ HTTP API è®¾è®¡æœ‰å‚è€ƒä»·å€¼",
            "used_by": ["http_service.py"],
        },
        "scripts/evaluator.py": {
            "necessity": "å»ºè®®å¤åˆ¶",
            "reason": "è¯„ä¼°è„šæœ¬ï¼Œå¯ç”¨äºæµ‹è¯• playbook è´¨é‡",
            "used_by": ["tests/", "critic.py"],
        },
        "scripts/orchestrator.py": {
            "necessity": "å¯é€‰å¤åˆ¶",
            "reason": "å¤šä»£ç†ç¼–æ’ï¼Œå½“å‰ä¸ºå•ä»£ç†æ¶æ„",
            "used_by": [],
        },
        "references/tool_patterns.md": {
            "necessity": "å»ºè®®å¤åˆ¶",
            "reason": "Tool è®¾è®¡æ¨¡å¼æ–‡æ¡£ï¼Œè¡¥å…… SKILL.md çš„ç»†èŠ‚",
            "used_by": ["http_service.py è®¾è®¡å‚è€ƒ"],
        },
        "references/metrics.md": {
            "necessity": "å»ºè®®å¤åˆ¶",
            "reason": "è¯„ä¼°æŒ‡æ ‡å®šä¹‰ï¼Œå¯¹ critic.py æœ‰å‚è€ƒä»·å€¼",
            "used_by": ["critic.py"],
        },
    }
    
    for file_path, info in file_necessity.items():
        analysis[info["necessity"]].append({
            "file": file_path,
            "reason": info["reason"],
            "used_by": info["used_by"],
        })
    
    return analysis


def print_necessity_report() -> None:
    """æ‰“å°å…³è”æ–‡ä»¶å¤åˆ¶å¿…è¦æ€§æŠ¥å‘Š"""
    analysis = analyze_file_necessity()
    
    print("\n" + "=" * 60)
    print("å…³è”æ–‡ä»¶å¤åˆ¶å¿…è¦æ€§åˆ†æ")
    print("=" * 60)
    
    categories = [
        ("å¿…éœ€å¤åˆ¶", "ğŸ”´"),
        ("å»ºè®®å¤åˆ¶", "ğŸŸ¡"),
        ("å¯é€‰å¤åˆ¶", "ğŸŸ¢"),
        ("æ— éœ€å¤åˆ¶", "âšª"),
    ]
    
    for category, icon in categories:
        files = analysis[category]
        if files:
            print(f"\n{icon} {category} ({len(files)} ä¸ªæ–‡ä»¶)")
            for f in files:
                print(f"   Â· {f['file']}")
                print(f"     ç†ç”±: {f['reason']}")
                if f['used_by']:
                    print(f"     å…³è”: {', '.join(f['used_by'])}")
    
    print("\n" + "-" * 60)
    print("å»ºè®®:")
    print("  1. ä½¿ç”¨ --flat (é»˜è®¤) ä»…åŒæ­¥ SKILL.md ä½œä¸ºçŸ¥è¯†æ–‡æ¡£")
    print("  2. ä½¿ç”¨ --full åŒæ­¥å®Œæ•´ç›®å½•ä»¥è·å–ç¤ºä¾‹è„šæœ¬")
    print("  3. scripts/ ä¸­çš„ä»£ç ä¸»è¦ç”¨äºæ¼”ç¤ºæ¦‚å¿µï¼Œéç”Ÿäº§ä¾èµ–")
    print("")


# =============================================================================
# Analysis Functions
# =============================================================================

def analyze_skill_usage(project_dir: str = ".") -> Dict[str, Any]:
    """åˆ†æé¡¹ç›®ä¸­ skills çš„ä½¿ç”¨æƒ…å†µ"""
    project = Path(project_dir)
    
    analysis = {
        "skills_loader_imported": False,
        "skills_loaded": [],
        "skills_referenced": [],
        "integration_points": [],
        "recommendations": [],
    }
    
    for py_file in project.rglob("*.py"):
        if "__pycache__" in str(py_file):
            continue
        
        try:
            content = py_file.read_text(encoding="utf-8")
        except Exception:
            continue
        
        rel_path = str(py_file.relative_to(project))
        
        if "skills_loader" in content or "SkillsPack" in content:
            analysis["skills_loader_imported"] = True
            analysis["integration_points"].append({
                "file": rel_path,
                "type": "import",
                "note": "Skills loader imported but usage unclear"
            })
        
        for skill_name in KNOWN_SKILLS:
            if skill_name in content:
                analysis["skills_referenced"].append({
                    "file": rel_path,
                    "skill": skill_name
                })
        
        patterns = {
            "compression": r"compress|compaction|layered.?summar",
            "degradation": r"lost.?in.?middle|context.?poison|drift",
            "memory": r"short.?term.?memory|long.?term.?memory|knowledge.?graph",
            "progressive_disclosure": r"progressive.?disclosure|on.?demand",
        }
        
        for concept, pattern in patterns.items():
            if re.search(pattern, content, re.I):
                analysis["integration_points"].append({
                    "file": rel_path,
                    "type": "concept",
                    "concept": concept
                })
    
    if not analysis["skills_loader_imported"]:
        analysis["recommendations"].append(
            "SkillsPack æœªè¢«å¯¼å…¥ä½¿ç”¨ - è€ƒè™‘åœ¨ pipeline.py æˆ– agentic_pipeline.py ä¸­é›†æˆ"
        )
    
    if not analysis["skills_referenced"]:
        analysis["recommendations"].append(
            "ä»£ç ä¸­æœªç›´æ¥å¼•ç”¨ä»»ä½• skill åç§° - skills å¯èƒ½ä»…ä½œä¸ºæ–‡æ¡£å­˜åœ¨"
        )
    
    compressor_path = project / "app" / "code2doc" / "compressor.py"
    if compressor_path.exists():
        analysis["integration_points"].append({
            "file": "app/code2doc/compressor.py",
            "type": "implementation",
            "concept": "context-compression",
            "note": "Implements compression principles from context-optimization skill"
        })
    
    return analysis


def print_usage_report(analysis: Dict[str, Any]) -> None:
    """æ‰“å°ä½¿ç”¨æƒ…å†µæŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("Skills ä½¿ç”¨æƒ…å†µåˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    print(f"\n[Skills Loader é›†æˆçŠ¶æ€]")
    if analysis["skills_loader_imported"]:
        print("  âœ“ SkillsPack å·²è¢«å¯¼å…¥")
    else:
        print("  âœ— SkillsPack æœªè¢«å¯¼å…¥")
    
    print(f"\n[Skills å¼•ç”¨æƒ…å†µ]")
    if analysis["skills_referenced"]:
        for ref in analysis["skills_referenced"]:
            print(f"  Â· {ref['skill']} in {ref['file']}")
    else:
        print("  (æ— ç›´æ¥å¼•ç”¨)")
    
    print(f"\n[æ¦‚å¿µå®ç°ç‚¹]")
    seen = set()
    for point in analysis["integration_points"]:
        key = f"{point['file']}:{point.get('concept', point.get('type'))}"
        if key not in seen:
            seen.add(key)
            note = point.get("note", "")
            print(f"  Â· {point['file']}: {point.get('concept', point['type'])}")
            if note:
                print(f"    â†’ {note}")
    
    print(f"\n[å»ºè®®]")
    for rec in analysis["recommendations"]:
        print(f"  âš  {rec}")
    
    print("")


# =============================================================================
# Main
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Sync skills from Agent-Skills-for-Context-Engineering (ä¿®å¤ç‰ˆ)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python scripts/sync_skills.py                    # æ‰å¹³æ¨¡å¼åŒæ­¥ SKILL.md
  python scripts/sync_skills.py --full             # å®Œæ•´ç›®å½•åŒæ­¥ (å« scripts/) - åŠ¨æ€å‘ç°
  python scripts/sync_skills.py --analyze          # åˆ†æé¡¹ç›®ä¸­çš„ä½¿ç”¨æƒ…å†µ
  python scripts/sync_skills.py --necessity        # åˆ†æå…³è”æ–‡ä»¶å¤åˆ¶å¿…è¦æ€§
  python scripts/sync_skills.py --include context-optimization,tool-design

ä¿®å¤å†…å®¹:
  - æ·»åŠ åŠ¨æ€å‘ç°å­ç›®å½•æ–‡ä»¶åŠŸèƒ½ (é€šè¿‡ GitHub API)
  - ä¸å†ä»…ä¾èµ–ç¡¬ç¼–ç çš„ KNOWN_SKILL_FILES åˆ—è¡¨
  - æ‰€æœ‰ skill çš„å­ç›®å½•æ–‡ä»¶éƒ½èƒ½è¢«æ­£ç¡®ä¸‹è½½
"""
    )
    parser.add_argument(
        "--target-dir", "-t",
        default="skills",
        help="Target directory for skills (default: skills/)"
    )
    parser.add_argument(
        "--force", "-f",
        action="store_true",
        help="Force overwrite existing files"
    )
    parser.add_argument(
        "--dry-run", "-n",
        action="store_true",
        help="Show what would be done without making changes"
    )
    parser.add_argument(
        "--include",
        help="Only sync specified skills (comma-separated)"
    )
    parser.add_argument(
        "--exclude",
        help="Exclude specified skills (comma-separated)"
    )
    parser.add_argument(
        "--analyze",
        action="store_true",
        help="Analyze skill usage in the project"
    )
    parser.add_argument(
        "--necessity",
        action="store_true",
        help="Analyze necessity of copying associated files"
    )
    parser.add_argument(
        "--flat",
        action="store_true",
        default=True,
        help="Use flat file structure - only SKILL.md (default)"
    )
    parser.add_argument(
        "--full",
        action="store_true",
        help="Sync full directory structure including scripts/, references/, assets/"
    )
    
    args = parser.parse_args()
    
    if args.necessity:
        print_necessity_report()
        return 0
    
    if args.analyze:
        analysis = analyze_skill_usage(".")
        print_usage_report(analysis)
        return 0
    
    include = set(args.include.split(",")) if args.include else None
    exclude = set(args.exclude.split(",")) if args.exclude else None
    
    flat_structure = not args.full
    
    syncer = SkillSyncer(
        target_dir=args.target_dir,
        force=args.force,
        dry_run=args.dry_run,
        include=include,
        exclude=exclude,
        flat_structure=flat_structure,
    )
    
    mode = "æ‰å¹³æ–‡ä»¶ (ä»… SKILL.md)" if flat_structure else "å®Œæ•´ç›®å½• (åŠ¨æ€å‘ç°å­æ–‡ä»¶)"
    print(f"åŒæ­¥ Skills åˆ° {args.target_dir}/")
    print(f"æ¨¡å¼: {mode}")
    if args.dry_run:
        print("(DRY RUN - ä¸å®é™…ä¿®æ”¹)")
    print("")
    
    results = syncer.sync_all()
    
    syncer.print_summary()
    
    downloaded = sum(1 for r in results if r.action in ("downloaded", "updated"))
    if not args.dry_run and downloaded > 0:
        print("\nç”Ÿæˆ skill_index.json...")
        index_path = syncer.save_index()
        print(f"  â†’ {index_path}")
    
    print("\n[é›†æˆå»ºè®®]")
    print("  è¦åœ¨ Code2Doc ä¸­ä½¿ç”¨åŒæ­¥çš„ skillsï¼Œè¯·åœ¨ pipeline.py ä¸­æ·»åŠ :")
    print("")
    print("    from app.code2doc.skills_loader import SkillsPack")
    print("    skills = SkillsPack('skills')")
    print("    compression_guide = skills.load('context-optimization')")
    print("")
    
    if flat_structure:
        print("  [æç¤º] ä½¿ç”¨ --full å¯åŒæ­¥å®Œæ•´ç›®å½•ç»“æ„ (åŒ…å«ç¤ºä¾‹è„šæœ¬)")
        print("         ä¿®å¤ç‰ˆæœ¬ä¼šè‡ªåŠ¨å‘ç°æ‰€æœ‰å­ç›®å½•æ–‡ä»¶")
    
    failed = sum(1 for r in results if r.action == "failed")
    return 0 if failed == 0 else 1


if __name__ == "__main__":
    sys.exit(main())